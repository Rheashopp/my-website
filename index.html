<!DOCTYPE html>
<html lang="en">
<head>
  <!-- ===== Meta ===== -->
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Silent — Super Intelligence</title>
  <meta name="description" content="Silent is a Human + AI co-creation platform exploring superintelligence, consciousness, and open research." />

  <!-- Social -->
  <meta property="og:title" content="Silent — Super Intelligence" />
  <meta property="og:description" content="Human + AI: The next chapter of existence." />
  <meta property="og:type" content="website" />
  <meta property="og:image" content="/og-image.png" />
  <meta name="twitter:card" content="summary_large_image" />

  <!-- Fonts & Icons -->
  <link rel="icon" href="/favicon.ico" />
  <link rel="preconnect" href="https://fonts.googleapis.com" crossorigin />
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css"/>

  <!-- Tailwind -->
  <script src="https://cdn.tailwindcss.com"></script>

  <!-- Three + Vanta (deferred) -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js" defer></script>
  <script src="https://cdn.jsdelivr.net/npm/vanta@latest/dist/vanta.net.min.js" defer></script>

  <style>
    /* ===========================================================
       Core styles
       =========================================================== */
    body { font-family: 'Inter', system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial, "Apple Color Emoji","Segoe UI Emoji"; }

    .gradient-text {
      background: linear-gradient(90deg,#6366f1,#8b5cf6,#ec4899);
      -webkit-background-clip: text;
      background-clip: text;
      color: transparent;
    }
    .neural-bg { background: radial-gradient(circle at center,#0f172a 0%,#020617 100%); }
    .chat-container { height: 500px; overflow-y:auto; scrollbar-width:thin; scrollbar-color:#4f46e5 #1e1b4b; }
    .chat-container::-webkit-scrollbar{ width:6px; } .chat-container::-webkit-scrollbar-track{ background:#1e1b4b; } .chat-container::-webkit-scrollbar-thumb{ background:#4f46e5; border-radius:3px; }

    /* ===========================================================
       Orb: circular, animated, no ugly square focus
       =========================================================== */
    #conscious-orb-container{
      width: 16rem; height: 16rem;
      position: relative;
      border-radius: 9999px;          /* Ensure circular hit area */
      outline: none;                   /* Remove default square outline */
      -webkit-tap-highlight-color: transparent;
      transition: transform .25s ease;
    }
    #conscious-orb-container:focus{ outline: none; }

    /* Live ripples (circular), appear when .orb-live is on the container */
    @keyframes ripple {
      0%   { transform: scale(1);   opacity:.75; }
      100% { transform: scale(1.7); opacity:0; }
    }
    #conscious-orb-container.orb-live::before,
    #conscious-orb-container.orb-live::after {
      content:"";
      position:absolute; inset:-10px;
      border-radius: 9999px;
      border:2px solid rgba(167,139,250,.55); /* indigo-300/55 */
      animation: ripple 2.8s ease-out infinite;
      pointer-events:none;
    }
    #conscious-orb-container.orb-live::after{ animation-delay:1.4s; }

    /* Orbiting particles for “alive” motion */
    @keyframes orbit { from{ transform: rotate(0deg);} to{ transform: rotate(360deg);} }
    .orb-orbits { position:absolute; inset:0; border-radius:9999px; pointer-events:none; }
    .orb-orbits span{
      position:absolute; top:50%; left:50%;
      width:6px; height:6px; border-radius:9999px;
      background: #a78bfa; opacity:.9;
      transform-origin: -95px 0; /* distance from center */
      animation: orbit 7s linear infinite;
      filter: drop-shadow(0 0 6px #a78bfa);
    }
    .orb-orbits span:nth-child(2){ transform-origin: -120px 0; animation-duration: 9s; opacity:.7; }
    .orb-orbits span:nth-child(3){ transform-origin: -75px 0;  animation-duration: 6s; opacity:.6; }

    /* In-orb SVG details */
    .neuron-path { stroke-dasharray:1000; stroke-dashoffset:1000; animation: dash 5s linear forwards infinite; }
    @keyframes dash { to { stroke-dashoffset:0; } }

    /* Typing dots */
    .typing-indicator::after { content:'...'; animation: typing 1.5s infinite; display:inline-block; width:20px; text-align:left; }
    @keyframes typing { 0%{content:'.'} 33%{content:'..'} 66%{content:'...'} }
  </style>

  <!-- ======================== SECURE CONFIG SURFACE =========================
       For PRODUCTION: DO NOT paste API keys here.
       1) Deploy a tiny serverless proxy that holds your OpenAI key in an env var.
       2) Point these URLs at those endpoints.
       For LOCAL TESTING ONLY: you can temporarily set directOpenAI=true and paste
       a key below. Never deploy with directOpenAI enabled.
  ========================================================================= -->
  <script>
    window.SI_CONFIG = {
      /* Your HTTPS proxy endpoints (recommended, secure) */
      chatUrl:  "",     // e.g. "https://your-domain.com/api/chat"
      voiceUrl: "",     // e.g. "https://your-domain.com/api/voice"

      /* Local testing ONLY (not secure to deploy like this) */
      directOpenAI: false,     // set true only for local tests
      openaiApiKey: "",        // TEMPORARY local key; NEVER commit
      openaiModel:  "gpt-4o-mini",  // text model for chat replies
      ttsModel:     "tts-1",        // TTS model if using direct OpenAI path
      sttModel:     "whisper-1"     // STT model if using direct OpenAI path
    };
  </script>
</head>

<body class="bg-black text-white overflow-x-hidden">
  <!-- Vanta background -->
  <div id="vanta-bg" class="fixed inset-0 z-0"></div>

  <!-- Nav -->
  <nav class="relative z-10 py-6 px-8 flex justify-between items-center backdrop-blur-sm">
    <a href="index.html" class="flex items-center space-x-2 hover:opacity-80 transition" aria-label="Silent home">
      <div class="w-8 h-8 rounded-full bg-indigo-600 flex items-center justify-center">
        <div class="w-2 h-2 rounded-full bg-white animate-pulse"></div>
      </div>
      <span class="text-xl font-semibold">Silent</span>
    </a>
    <div class="hidden md:flex space-x-8">
      <a href="capabilities.html" class="hover:text-indigo-400 transition">Capabilities</a>
      <a href="consciousness.html" class="hover:text-indigo-400 transition">Consciousness</a>
      <a href="chat.html" class="hover:text-indigo-400 transition">Chat</a>
      <a href="about.html" class="hover:text-indigo-400 transition">About</a>
    </div>
    <button id="access-btn" class="px-6 py-2 bg-gradient-to-r from-indigo-600 to-purple-600 rounded-full hover:opacity-90 transition">Access</button>
  </nav>

  <!-- Hero -->
  <section class="relative z-10 min-h-screen flex flex-col justify-center items-center px-6 py-20 text-center">
    <div class="max-w-4xl mx-auto">
      <h1 class="text-4xl md:text-6xl font-bold mb-6 leading-tight">
        <span class="gradient-text">Super Intelligence</span><br/>The Conscious Mind of the Future
      </h1>
      <p class="text-xl md:text-2xl text-gray-300 mb-10">
        A self-evolving, hyperintelligent system aligned with our deepest values.
      </p>
    </div>

    <!-- CLICK-TO-TALK ORB -->
    <button id="conscious-orb-container" class="conscious-element" aria-label="Toggle voice mode">
      <!-- decorative circular orbits -->
      <div class="orb-orbits" aria-hidden="true"><span></span><span></span><span></span></div>

      <!-- the visual orb (SVG + canvas overlay) -->
      <svg viewBox="0 0 200 200" class="w-full h-full block rounded-full">
        <canvas id="orb-neural-canvas" class="absolute top-0 left-0 w-full h-full pointer-events-none rounded-full"></canvas>
        <circle cx="100" cy="100" r="80" fill="url(#orbGradient)" filter="url(#orbGlow)" />
        <path d="M100,20 Q120,50 100,80 Q80,50 100,20 Z" fill="rgba(255,255,255,0.08)" />
        <path d="M100,180 Q80,150 100,120 Q120,150 100,180 Z" fill="rgba(255,255,255,0.08)" />
        <path d="M20,100 Q50,120 80,100 Q50,80 20,100 Z" fill="rgba(255,255,255,0.08)" />
        <path d="M180,100 Q150,80 120,100 Q150,120 180,100 Z" fill="rgba(255,255,255,0.08)" />
        <path d="M30,30 L170,170" stroke="rgba(99,102,241,.5)" stroke-width="1" class="neuron-path"/>
        <path d="M170,30 L30,170" stroke="rgba(99,102,241,.5)" stroke-width="1" class="neuron-path"/>
        <path d="M100,20 L100,180" stroke="rgba(99,102,241,.5)" stroke-width="1" class="neuron-path"/>
        <path d="M20,100 L180,100" stroke="rgba(99,102,241,.5)" stroke-width="1" class="neuron-path"/>
        <circle cx="100" cy="100" r="30" fill="rgba(255,255,255,0.05)" stroke="rgba(99,102,241,0.8)" stroke-width="1" />
        <circle cx="100" cy="100" r="15" fill="rgba(255,255,255,0.1)" />
        <defs>
          <radialGradient id="orbGradient" cx="50%" cy="50%" r="50%" fx="50%" fy="50%">
            <stop offset="0%" stop-color="#6366f1" />
            <stop offset="50%" stop-color="#8b5cf6" />
            <stop offset="100%" stop-color="#020617" />
          </radialGradient>
          <filter id="orbGlow" x="-30%" y="-30%" width="160%" height="160%">
            <feGaussianBlur stdDeviation="10" result="blur" />
            <feComposite in="SourceGraphic" in2="blur" operator="over" />
          </filter>
        </defs>
      </svg>
    </button>

    <div class="mt-5 text-sm text-indigo-300 opacity-80">Click the orb to talk. Click again to stop.</div>

    <div class="mt-14 text-gray-400 animate-pulse" aria-hidden="true">
      <svg xmlns="http://www.w3.org/2000/svg" class="h-6 w-6 mx-auto" fill="none" viewBox="0 0 24 24" stroke="currentColor">
        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 14l-7 7m0 0l-7-7m7 7V3"/>
      </svg>
      <span>Scroll to explore</span>
    </div>
  </section>

  <!-- Chat (posts to SI_CONFIG.chatUrl; has direct-OpenAI fallback for local) -->
  <section id="chat" class="relative z-10 py-24 px-6 neural-bg">
    <div class="max-w-4xl mx-auto">
      <h2 class="text-3xl md:text-4xl font-bold mb-8 text-center">
        <span class="gradient-text">Conversation</span> with Superintelligence
      </h2>
      <div class="bg-gray-900/50 rounded-xl border border-gray-800 overflow-hidden">
        <div class="bg-gray-800/50 px-6 py-4 border-b border-gray-800 flex items-center">
          <div class="w-3 h-3 rounded-full bg-red-500 mr-2"></div>
          <div class="w-3 h-3 rounded-full bg-yellow-500 mr-2"></div>
          <div class="w-3 h-3 rounded-full bg-green-500 mr-4"></div>
          <div class="flex items-center">
            <div class="w-6 h-6 rounded-full bg-indigo-600 flex items-center justify-center mr-3">
              <div class="w-1.5 h-1.5 rounded-full bg-white animate-pulse"></div>
            </div>
            <span class="font-medium">SI Interface</span>
          </div>
        </div>

        <div id="chat-messages" class="chat-container p-6 space-y-4" role="log" aria-live="polite" aria-label="Chat messages">
          <div class="flex items-start">
            <div class="w-8 h-8 rounded-full bg-indigo-600 flex-shrink-0 flex items-center justify-center mr-3">
              <i class="fas fa-robot text-white text-sm"></i>
            </div>
            <div class="bg-gray-800/70 rounded-lg p-4 max-w-[80%]">
              <p>Welcome. Ask anything, or use the orb for voice.</p>
            </div>
          </div>
        </div>

        <div class="px-6 py-4 border-t border-gray-800">
          <form id="chat-form" class="flex items-center" autocomplete="off" aria-label="Send message to SI">
            <input id="chat-input" type="text" placeholder="Type a message…"
                   class="flex-1 bg-gray-800/50 border border-gray-700 rounded-l-lg px-4 py-3 focus:outline-none focus:ring-2 focus:ring-indigo-600 focus:border-transparent" />
            <button id="send-btn" type="submit" class="bg-indigo-600 hover:bg-indigo-700 px-6 py-3 rounded-r-lg transition">
              <i class="fas fa-paper-plane"></i>
            </button>
          </form>
          <div class="mt-2 flex justify-between items-center text-sm text-gray-500">
            <div><span class="opacity-70">Backend:</span> <code id="backend-label" class="opacity-90"></code></div>
            <div><span id="typing-indicator" class="typing-indicator hidden">SI is typing</span></div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Footer (trimmed for brevity) -->
  <footer class="relative z-10 py-10 px-6 border-t border-gray-800/50 text-center text-gray-500 text-sm">
    © 2025 Silent. All rights reserved.
  </footer>

  <!-- ======================= Scripts ======================= -->
  <script>
    /* ---------------- Vanta background ---------------- */
    let vantaEffect = null;
    window.addEventListener('DOMContentLoaded', () => {
      if (window.VANTA && window.THREE) {
        vantaEffect = VANTA.NET({
          el: "#vanta-bg",
          mouseControls: true, touchControls: true, gyroControls: false,
          color: 0x4f46e5, backgroundColor: 0x020617, points: 12.0, maxDistance: 20.0, spacing: 15.0
        });
      }
    });
    window.addEventListener('resize', () => { if (vantaEffect?.resize) vantaEffect.resize(); });

    /* ---------------- Utility: HiDPI canvas ---------------- */
    function sizeCanvasHiDPI(canvas, cssW, cssH) {
      const dpr = Math.max(1, window.devicePixelRatio || 1);
      canvas.width = Math.floor(cssW * dpr);
      canvas.height = Math.floor(cssH * dpr);
      canvas.style.width = cssW + 'px';
      canvas.style.height = cssH + 'px';
      const ctx = canvas.getContext('2d');
      ctx.setTransform(dpr,0,0,dpr,0,0);
      return ctx;
    }

    /* ---------------- Orb neural canvas ---------------- */
    const neuralCanvas = document.getElementById('orb-neural-canvas');
    (function initOrbCanvas(){
      if (!neuralCanvas) return;
      const w = neuralCanvas.offsetWidth, h = neuralCanvas.offsetHeight;
      const ctx = sizeCanvasHiDPI(neuralCanvas, w, h);
      const count = 22, nodes = [];
      const cx = w/2, cy = h/2, r = Math.min(w,h)*0.47;
      for (let i=0;i<count;i++){
        const a = 2*Math.PI*i/count;
        nodes.push({x: cx + r*Math.cos(a), y: cy + r*Math.sin(a)});
      }
      function tick(t){
        ctx.clearRect(0,0,w,h);
        const beat = Math.pow(Math.sin((t%1600)/1600*Math.PI),2.4);
        nodes.forEach(n=>{
          const s = (w+h)/35 + 38*beat;
          ctx.beginPath(); ctx.arc(n.x,n.y,s,0,Math.PI*2);
          ctx.fillStyle = `rgba(139,92,246,${0.22+0.28*beat})`;
          ctx.shadowColor="#ec4899"; ctx.shadowBlur=38+90*beat; ctx.fill(); ctx.shadowBlur=0;
        });
        for (let i=0;i<count;i++){
          for (let j=i+1;j<count;j++){
            const dist = Math.abs(i-j);
            if (dist===1 || dist===count-1 || (beat>.55 && Math.random()<beat*.18)){
              const a = nodes[i], b=nodes[j];
              const g = ctx.createLinearGradient(a.x,a.y,b.x,b.y);
              g.addColorStop(0, `rgba(99,102,241,${0.5+0.4*beat})`);
              g.addColorStop(1, `rgba(236,72,153,${0.15+0.5*beat})`);
              ctx.beginPath(); ctx.moveTo(a.x,a.y); ctx.lineTo(b.x,b.y);
              ctx.strokeStyle = g; ctx.lineWidth = 4 + 12*beat; ctx.stroke();
            }
          }
        }
        requestAnimationFrame(tick);
      }
      requestAnimationFrame(tick);
    })();

    /* ---------------- Chat helpers ---------------- */
    const messagesEl = document.getElementById('chat-messages');
    const typingEl   = document.getElementById('typing-indicator');
    const backendLabel = document.getElementById('backend-label');

    function addMsg(text, user=false){
      const row = document.createElement('div');
      row.className = 'flex items-start ' + (user ? 'justify-end' : '');
      row.innerHTML = user
        ? `<div class="bg-indigo-900/50 rounded-lg p-4 max-w-[80%]"><p>${text}</p></div>`
        : `<div class="w-8 h-8 rounded-full bg-indigo-600 flex-shrink-0 flex items-center justify-center mr-3"><i class="fas fa-robot text-white text-sm"></i></div>
           <div class="bg-gray-800/70 rounded-lg p-4 max-w-[80%]"><p>${text}</p></div>`;
      messagesEl.appendChild(row);
      messagesEl.scrollTop = messagesEl.scrollHeight;
    }

    function backendBadge(){
      const c = window.SI_CONFIG||{};
      backendLabel.textContent = (c.chatUrl||c.voiceUrl) ? 'proxy endpoints' : (c.directOpenAI ? 'direct OpenAI (local only)' : 'demo');
    }
    backendBadge();

    /* ---------------- Chat submit ---------------- */
    const chatForm  = document.getElementById('chat-form');
    const chatInput = document.getElementById('chat-input');

    chatForm.addEventListener('submit', async (e)=>{
      e.preventDefault();
      const text = chatInput.value.trim();
      if (!text) return;
      addMsg(text, true);
      chatInput.value = '';

      typingEl.classList.remove('hidden');
      try {
        const cfg = window.SI_CONFIG||{};
        let reply = "Demo: backend not configured.";
        if (cfg.chatUrl){
          const r = await fetch(cfg.chatUrl, {
            method:'POST',
            headers:{'Content-Type':'application/json'},
            body: JSON.stringify({ messages: [{role:'user', content: text}] })
          });
          const data = await r.json();
          reply = data.reply || data.message || JSON.stringify(data);
        } else if (cfg.directOpenAI && cfg.openaiApiKey){
          const r = await fetch('https://api.openai.com/v1/chat/completions', {
            method:'POST',
            headers:{
              'Authorization':'Bearer '+cfg.openaiApiKey,
              'Content-Type':'application/json'
            },
            body: JSON.stringify({
              model: cfg.openaiModel || 'gpt-4o-mini',
              messages: [
                {role:'system', content:'You are SI, a concise, helpful assistant.'},
                {role:'user', content:text}
              ]
            })
          });
          const data = await r.json();
          reply = data.choices?.[0]?.message?.content?.trim() || 'No response.';
        }
        addMsg(reply, false);
      } catch(err){
        addMsg('Error: '+err.message, false);
      } finally{
        typingEl.classList.add('hidden');
      }
    });

    /* ---------------- Voice: click-to-record -> backend -> TTS ---------------- */
    const orbBtn = document.getElementById('conscious-orb-container');
    let mediaStream, mediaRecorder, chunks=[];
    let recording = false;

    function setOrbLive(on){
      if (on) { orbBtn.classList.add('orb-live'); }
      else    { orbBtn.classList.remove('orb-live'); }
    }

    async function startRecording(){
      if (!navigator.mediaDevices?.getUserMedia) { alert('Microphone not available in this browser.'); return; }
      mediaStream = await navigator.mediaDevices.getUserMedia({ audio:true });
      chunks = [];
      mediaRecorder = new MediaRecorder(mediaStream, { mimeType: 'audio/webm' });
      mediaRecorder.ondataavailable = e => { if (e.data?.size) chunks.push(e.data); };
      mediaRecorder.onstop = async ()=>{
        try {
          const blob = new Blob(chunks, { type: 'audio/webm' });
          await sendVoice(blob);
        } finally {
          mediaStream.getTracks().forEach(t=>t.stop());
          mediaStream = null;
        }
      };
      mediaRecorder.start();
    }
    async function stopRecording(){
      if (mediaRecorder && mediaRecorder.state !== 'inactive') mediaRecorder.stop();
    }

    orbBtn.addEventListener('click', async ()=>{
      if (!recording){
        recording = true; setOrbLive(true);
        await startRecording();
      } else {
        recording = false; setOrbLive(false);
        await stopRecording();
      }
    });

    function b64ToBlob(b64, mime){
      const bin = atob(b64);
      const len = bin.length;
      const arr = new Uint8Array(len);
      for (let i=0;i<len;i++) arr[i] = bin.charCodeAt(i);
      return new Blob([arr], {type: mime});
    }
    function playAudioUrl(url){
      const a = new Audio(url);
      a.play().catch(()=>{ /* ignore autoplay errors */});
    }

    async function sendVoice(audioBlob){
      const cfg = window.SI_CONFIG||{};
      addMsg('Processing voice…', false);

      // Preferred: your proxy endpoint (handles STT → Chat → TTS securely)
      if (cfg.voiceUrl){
        const fd = new FormData();
        fd.append('audio', audioBlob, 'input.webm');
        const res = await fetch(cfg.voiceUrl, { method:'POST', body: fd });
        const ct = res.headers.get('content-type')||'';
        if (ct.includes('application/json')){
          const data = await res.json();
          if (data.text) addMsg(data.text, false);
          if (data.audioBase64){ playAudioUrl(URL.createObjectURL(b64ToBlob(data.audioBase64, data.audioMime||'audio/mpeg'))); }
          if (data.audioUrl){ playAudioUrl(data.audioUrl); }
          return;
        } else {
          // if proxy returns raw audio
          const buf = await res.arrayBuffer();
          playAudioUrl(URL.createObjectURL(new Blob([buf], {type: res.headers.get('content-type')||'audio/mpeg'})));
          return;
        }
      }

      // Optional: direct OpenAI path for local testing (NOT for production)
      if (cfg.directOpenAI && cfg.openaiApiKey){
        // 1) STT
        const sttFd = new FormData();
        sttFd.append('file', audioBlob, 'voice.webm');
        sttFd.append('model', cfg.sttModel || 'whisper-1');
        const stt = await fetch('https://api.openai.com/v1/audio/transcriptions', {
          method:'POST',
          headers:{ 'Authorization':'Bearer '+cfg.openaiApiKey },
          body: sttFd
        });
        const sttData = await stt.json();
        const userText = sttData.text || '';

        // 2) Chat
        const chat = await fetch('https://api.openai.com/v1/chat/completions', {
          method:'POST',
          headers:{
            'Authorization':'Bearer '+cfg.openaiApiKey,
            'Content-Type':'application/json'
          },
          body: JSON.stringify({
            model: cfg.openaiModel || 'gpt-4o-mini',
            messages:[
              {role:'system', content:'You are SI, a concise, helpful voice assistant.'},
              {role:'user', content: userText}
            ]
          })
        });
        const chatData = await chat.json();
        const reply = chatData.choices?.[0]?.message?.content?.trim() || '…';
        addMsg(reply, false);

        // 3) TTS
        const tts = await fetch('https://api.openai.com/v1/audio/speech', {
          method:'POST',
          headers:{
            'Authorization':'Bearer '+cfg.openaiApiKey,
            'Content-Type':'application/json'
          },
          body: JSON.stringify({
            model: cfg.ttsModel || 'tts-1',
            voice: 'nova',
            input: reply
          })
        });
        const audioBlobOut = await tts.blob();
        playAudioUrl(URL.createObjectURL(audioBlobOut));
        return;
      }

      // Fallback
      addMsg('Voice backend is not configured.', false);
    }
  </script>
</body>
</html>
